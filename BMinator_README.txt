
BMINATÃ–R (DeepPersona): WORD-LEVEL TRANSFORMER TABANLI KÄ°ÅÄ°LÄ°K ODAKLI METÄ°N ÃœRETÄ°MÄ°
====================================================================================

GENEL AÃ‡IKLAMA
--------------
BMinatÃ¶r, kullanÄ±cÄ±ya ait 25 boyutlu "persona vektÃ¶rÃ¼" ile eÄŸitilmiÅŸ, Word-level Transformer mimarisi kullanan 
kiÅŸilik odaklÄ± bir metin Ã¼retim sistemidir. Bu sistem, bireyin karakteristik Ã¶zelliklerine gÃ¶re dil Ã§Ä±ktÄ±sÄ± Ã¼retir. 
Sesli yanÄ±t veya yÃ¼z animasyonu **bulunmamaktadÄ±r**.

YAZAR
-----
ğŸ‘©â€ğŸ’» BÃ¼ÅŸra Mina Al  
ğŸ“§ busraminaa@gmail.com  
ğŸ“ Ostim Teknik Ãœniversitesi â€“ Yapay Zeka MÃ¼hendisliÄŸi & EndÃ¼stri MÃ¼hendisliÄŸi (Ã‡AP)  
ğŸ§  UzmanlÄ±k: NLP, Ãœretken Yapay Zeka, KiÅŸilik OdaklÄ± AI Modelleri  

------------------------------------------------------------------------------------
1. BAÅLATMA TALÄ°MATLARI
------------------------------------------------------------------------------------

âœ… GEREKSÄ°NÄ°MLER:
-----------------
- Python 3.10+
- PyTorch
- NumPy
- scikit-learn

ğŸ§© GEREKLÄ° KURULUM:
-------------------

# AdÄ±m 1: Repository'yi klonla
git clone https://github.com/kullanici/bminator.git
cd bminator

# AdÄ±m 2: Gereksinimleri kur
pip install -r requirements.txt

ğŸš€ EÄÄ°TÄ°MÄ° BAÅLATMA:
--------------------

python train_word_transformer.py \
  --epochs 150 \
  --batch_size 64 \
  --save_dir checkpoints/

âœï¸ METÄ°N ÃœRETÄ°MÄ°:
------------------

python generate_word_level.py \
  --vector_file "sample.vec" \
  --model_checkpoint "checkpoints/model_150.pt"

ğŸ“ Ã‡IKTI:
---------
- Ãœretilen kelime dizisi: outputs/generated_text.txt

------------------------------------------------------------------------------------
2. MODEL TEKNÄ°K DETAYLARI
------------------------------------------------------------------------------------

ğŸ“Œ GÄ°RDÄ°LER:
-----------
- vector â†’ 25 float deÄŸerlik kiÅŸilik vektÃ¶rÃ¼
- text_ids â†’ vocab.jsonâ€™dan gelen token ID dizisi (maks. 60 uzunluk)

ğŸ“Œ TRANSFORMER MÄ°MARÄ°SÄ°:
-------------------------
- 4 adet Transformer blok
- 8 baÅŸlÄ±klÄ± Self-Attention
- Word Embedding boyutu: 128
- Dropout: %20
- Aktivasyon: ReLU
- Normalizasyon: LayerNorm
- Loss: CrossEntropy
- Optimizer: Adam (lr=0.0005)

ğŸ“Œ VERÄ° FORMATLARI:
-------------------
- word_vocab.json: Kelime-ID sÃ¶zlÃ¼ÄŸÃ¼ (ilk 5000 kelime)
- worddata_partX.json: Her satÄ±r { "vector": [...], "text_ids": [...] } biÃ§iminde

------------------------------------------------------------------------------------
3. NOTLAR & GELÄ°ÅTÄ°RME HEDEFLERÄ°
------------------------------------------------------------------------------------

âœ… Tamamlananlar:
- Word-level Ã¼retken Transformer modeli
- 20.000 Ã¶rnekten oluÅŸan 4 parÃ§alÄ± dataset
- EÄŸitim ve inference dÃ¶ngÃ¼sÃ¼

ğŸ§ª Planlananlar:
- GÃ¶rsel girdiden otomatik persona Ã§Ä±karÄ±mÄ±
- Duygu durumu temelli Ã¼retim vektÃ¶rÃ¼
- Gradio / Streamlit tabanlÄ± web arayÃ¼zÃ¼

------------------------------------------------------------------------------------
4. LÄ°SANS
------------------------------------------------------------------------------------

Bu proje MIT lisansÄ± ile lisanslanmÄ±ÅŸtÄ±r. Ticari veya akademik amaÃ§larla serbestÃ§e kullanÄ±labilir.

Telif HakkÄ± Â© 2025 BÃ¼ÅŸra Mina Al
