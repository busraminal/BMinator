{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNk2gb2iNBLRRD5COuNTbpU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"okowRDAkWPDq"},"outputs":[],"source":["\n","import os\n","os.environ[\"PYTORCH_NVFUSER_DISABLE\"] = \"1\"\n","os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n","\n","\n","import json\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n"]},{"cell_type":"code","source":["!pip install pillow\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hpHms3sCXBqG","executionInfo":{"status":"ok","timestamp":1747572302946,"user_tz":-180,"elapsed":8844,"user":{"displayName":"BÃ¼ÅŸra mina Al","userId":"10612169554875599726"}},"outputId":"d443634f-9b3a-4ea5-e87c-cb39bf840886"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n"]}]},{"cell_type":"code","source":["from PIL import Image\n","import numpy as np\n","\n","def extract_visual_embedding(image_path):\n","    img = Image.open(image_path).convert(\"RGB\")\n","    arr = np.array(img)\n","    h, w, _ = arr.shape\n","\n","    def crop_percent(x1, y1, x2, y2):\n","        return arr[int(y1*h):int(y2*h), int(x1*w):int(x2*w), :]\n","\n","    regions = {\n","        'eyes': crop_percent(0.3, 0.2, 0.7, 0.35),\n","        'mouth': crop_percent(0.35, 0.65, 0.65, 0.85),\n","        'nose': crop_percent(0.45, 0.4, 0.55, 0.6),\n","        'forehead': crop_percent(0.3, 0.05, 0.7, 0.2),\n","        'chin': crop_percent(0.4, 0.85, 0.6, 0.95)\n","    }\n","\n","    embeddings = {}\n","    for region_name, region in regions.items():\n","        flat = region.flatten() / 255.0\n","        embeddings[region_name] = np.concatenate([\n","            [np.mean(flat), np.std(flat)],\n","            np.percentile(flat, [25, 50, 75])\n","        ])\n","\n","    final_vector = np.concatenate([v for v in embeddings.values()])\n","    return final_vector  # Ã–rn: 25 boyutlu vektÃ¶r\n"],"metadata":{"id":"yO48dJKHXHbZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import json\n","import numpy as np\n","\n","def generate_fake_story(vector):\n","    base_sentences = [\n","        \"Tokatâ€™da doÄŸdum ve bÃ¼yÃ¼dÃ¼m.\",\n","        \"HayatÄ±m boyunca hep sanatla ilgilendim.\",\n","        \"Ã‡ocukluÄŸum kÃ¶yde geÃ§ti, Ã§ok huzurluydu.\",\n","        \"Her zaman yalnÄ±z bir insan oldum.\",\n","        \"Annem bana umutla yaÅŸamayÄ± Ã¶ÄŸretti.\",\n","        \"MÃ¼zik benim en iyi arkadaÅŸÄ±m oldu.\",\n","        \"Bazen sessizlikte kaybolurum.\",\n","        \"Hayat bana sabretmeyi Ã¶ÄŸretti.\",\n","        \"Ä°nsanlara yardÄ±m etmek beni mutlu eder.\",\n","        \"DuygularÄ±mÄ± kelimelere dÃ¶kmekte zorlanÄ±rÄ±m.\"\n","    ]\n","    return random.choice(base_sentences)\n","\n","def generate_dataset(output_file=\"training_data_1000.json\", count=1000):\n","    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n","        for _ in range(count):\n","            vec = np.random.rand(25).tolist()\n","            story = generate_fake_story(vec)\n","            item = {\"vector\": vec, \"text\": story}\n","            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n","    print(f\"âœ… Sentetik veri oluÅŸturuldu: {output_file} ({count} adet)\")\n"],"metadata":{"id":"puYKVI-rXPHF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import random\n","import json\n","import numpy as np\n","from google.colab import drive\n","\n","\n","drive.mount('/content/drive')\n","\n","\n","def generate_fake_story(vector):\n","    base_sentences = [\n","        \"Ä°stanbulâ€™da doÄŸdum ve bÃ¼yÃ¼dÃ¼m.\",\n","        \"HayatÄ±m boyunca hep sanatla ilgilendim.\",\n","        \"Ã‡ocukluÄŸum kÃ¶yde geÃ§ti, Ã§ok huzurluydu.\",\n","        \"Her zaman yalnÄ±z bir insan oldum.\",\n","        \"Annem bana umutla yaÅŸamayÄ± Ã¶ÄŸretti.\",\n","        \"Kitaplar benim en iyi arkadaÅŸÄ±m oldu.\",\n","        \"Bazen sessizlikte kaybolurum.\",\n","        \"Hayat bana sabretmeyi Ã¶ÄŸretti.\",\n","        \"Ä°nsanlara yardÄ±m etmek beni mutlu eder.\",\n","        \"DuygularÄ±mÄ± kelimelere dÃ¶kmekte zorlanÄ±rÄ±m.\"\n","    ]\n","    return random.choice(base_sentences)\n","\n","\n","def generate_dataset_and_save(count=5000, file_name=\"training_data_5000.json\"):\n","\n","    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n","        for _ in range(count):\n","            vec = np.random.rand(25).tolist()\n","            story = generate_fake_story(vec)\n","            item = {\"vector\": vec, \"text\": story}\n","            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n","\n","    print(f\"âœ… Sentetik veri oluÅŸturuldu: {file_name} ({count} adet)\")\n","\n","\n","    drive_path = f\"/content/drive/MyDrive/{file_name}\"\n","    !cp {file_name} {drive_path}\n","    print(f\"ğŸ“ Google Drive'a yÃ¼klendi: {drive_path}\")\n","\n","\n","generate_dataset_and_save()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sawk7ATYXnup","executionInfo":{"status":"ok","timestamp":1747572304764,"user_tz":-180,"elapsed":1771,"user":{"displayName":"BÃ¼ÅŸra mina Al","userId":"10612169554875599726"}},"outputId":"fbdf6fce-5e72-4d50-ab25-aca16c0a5a2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","âœ… Sentetik veri oluÅŸturuldu: training_data_5000.json (5000 adet)\n","ğŸ“ Google Drive'a yÃ¼klendi: /content/drive/MyDrive/training_data_5000.json\n"]}]},{"cell_type":"code","source":["\n","import os\n","os.environ[\"PYTORCH_NVFUSER_DISABLE\"] = \"1\"\n","os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n","\n","import json\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","\n","EMBED_DIM = 256\n","FF_DIM = 512\n","NUM_HEADS = 8\n","NUM_LAYERS = 4\n","MAX_LEN = 120               # METÄ°N BOYU DÃœÅÃœRÃœLDÃœ\n","EPOCHS = 50                 # DAHA HAFÄ°F EÄÄ°TÄ°M\n","BATCH_SIZE = 4              # BELLEK DOSTU\n","LEARNING_RATE = 5e-4\n","PATIENCE = 10\n","MIN_DELTA = 0.02\n","\n","\n","char_set = list(\"abcÃ§defgÄŸÄ±ijklmnoÃ¶prsÅŸtuÃ¼vyzABCÃ‡DEFGÄHIÄ°JKLMNOÃ–PRSÅTUÃœVYZ0123456789 .,!?-\\n\")\n","char2idx = {c: i for i, c in enumerate(char_set)}\n","idx2char = {i: c for c, i in char2idx.items()}\n","vocab_size = len(char2idx)\n","\n","def text_to_tensor(text):\n","    ids = [char2idx.get(c, 0) for c in text]\n","    ids += [0] * (MAX_LEN - len(ids))\n","    return torch.tensor(ids[:MAX_LEN])\n","\n","\n","class PersonaDataset(Dataset):\n","    def __init__(self, json_path):\n","        self.data = []\n","        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n","            for line in f:\n","                obj = json.loads(line)\n","                vec = torch.tensor(obj[\"vector\"]).float()\n","                txt = text_to_tensor(obj[\"text\"])\n","                self.data.append((vec, txt))\n","    def __len__(self): return len(self.data)\n","    def __getitem__(self, idx): return self.data[idx]\n","\n","\n","class ScaledDotProductAttention(nn.Module):\n","    def forward(self, Q, K, V):\n","        d_k = Q.size(-1)\n","        scores = torch.matmul(Q, K.transpose(-2, -1)) / d_k**0.5\n","        attn = torch.softmax(scores, dim=-1)\n","        return torch.matmul(attn, V)\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, embed_dim, num_heads):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.d_k = embed_dim // num_heads\n","        self.q_linear = nn.Linear(embed_dim, embed_dim)\n","        self.k_linear = nn.Linear(embed_dim, embed_dim)\n","        self.v_linear = nn.Linear(embed_dim, embed_dim)\n","        self.out = nn.Linear(embed_dim, embed_dim)\n","        self.attn = ScaledDotProductAttention()\n","    def forward(self, x):\n","        B, T, _ = x.size()\n","        Q = self.q_linear(x).view(B, T, self.num_heads, self.d_k).transpose(1, 2)\n","        K = self.k_linear(x).view(B, T, self.num_heads, self.d_k).transpose(1, 2)\n","        V = self.v_linear(x).view(B, T, self.num_heads, self.d_k).transpose(1, 2)\n","        scores = self.attn(Q, K, V)\n","        concat = scores.transpose(1, 2).contiguous().view(B, T, self.num_heads * self.d_k)\n","        return self.out(concat)\n","\n","class TransformerBlock(nn.Module):\n","    def __init__(self, embed_dim, num_heads, ff_dim):\n","        super().__init__()\n","        self.attn = MultiHeadAttention(embed_dim, num_heads)\n","        self.norm1 = nn.LayerNorm(embed_dim)\n","        self.ff = nn.Sequential(\n","            nn.Linear(embed_dim, ff_dim), nn.ReLU(), nn.Linear(ff_dim, embed_dim))\n","        self.norm2 = nn.LayerNorm(embed_dim)\n","    def forward(self, x):\n","        attn = self.attn(x)\n","        x = self.norm1(x + attn)\n","        ff = self.ff(x)\n","        return self.norm2(x + ff)\n","\n","class EmbeddingLayer(nn.Module):\n","    def __init__(self, input_dim, embed_dim):\n","        super().__init__()\n","        self.projection = nn.Sequential(\n","            nn.Linear(input_dim, embed_dim), nn.ReLU(), nn.LayerNorm(embed_dim))\n","    def forward(self, x): return self.projection(x)\n","\n","class CharDecoder(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, num_heads, ff_dim, num_layers):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        self.layers = nn.ModuleList([TransformerBlock(embed_dim, num_heads, ff_dim) for _ in range(num_layers)])\n","        self.output = nn.Linear(embed_dim, vocab_size)\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        for layer in self.layers: x = layer(x)\n","        return self.output(x)\n","\n","class LifeStoryModel(nn.Module):\n","    def __init__(self, persona_dim, vocab_size, embed_dim, num_heads, ff_dim, num_layers):\n","        super().__init__()\n","        self.embedding_layer = EmbeddingLayer(persona_dim, embed_dim)\n","        self.decoder = CharDecoder(vocab_size, embed_dim, num_heads, ff_dim, num_layers)\n","    def forward(self, persona_vec, target_seq):\n","        context = self.embedding_layer(persona_vec).unsqueeze(1)\n","        decoder_input = self.decoder.embedding(target_seq) + context\n","        for layer in self.decoder.layers:\n","            decoder_input = layer(decoder_input)\n","        return self.decoder.output(decoder_input)\n","\n","\n","print(\"ğŸ¯ Hafif eÄŸitim baÅŸladÄ± (max_len=120, batch=4, patience=3)\")\n","\n","model = LifeStoryModel(25, vocab_size, EMBED_DIM, NUM_HEADS, FF_DIM, NUM_LAYERS)\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","criterion = nn.CrossEntropyLoss()\n","\n","dataset = PersonaDataset(\"training_data_5000.json\")\n","loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","best_loss = float(\"inf\")\n","patience_counter = 0\n","\n","for epoch in range(EPOCHS):\n","    total_loss = 0\n","    model.train()\n","    for persona_vec, target_seq in loader:\n","        optimizer.zero_grad()\n","        output = model(persona_vec, target_seq[:, :-1])\n","        loss = criterion(output.reshape(-1, vocab_size), target_seq[:, 1:].reshape(-1))\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss:.4f}\")\n","\n","    if (epoch + 1) % 10 == 0:\n","        fname = f\"deeppersona_epoch{epoch+1}.pth\"\n","        torch.save(model.state_dict(), fname)\n","        print(f\" KayÄ±t tamamlandÄ±: {fname}\")\n","\n","    if best_loss - total_loss > MIN_DELTA:\n","        best_loss = total_loss\n","        patience_counter = 0\n","        torch.save(model.state_dict(), \"deeppersona_best.pth\")\n","    else:\n","        patience_counter += 1\n","        print(f\"â¸ï¸  No improvement. Patience: {patience_counter}/{PATIENCE}\")\n","        if patience_counter >= PATIENCE:\n","            print(f\"ğŸ›‘ Early stopping. Best Loss: {best_loss:.4f}\")\n","            break\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCtaD-8-YPnn","executionInfo":{"status":"ok","timestamp":1747585806090,"user_tz":-180,"elapsed":12897745,"user":{"displayName":"BÃ¼ÅŸra mina Al","userId":"10612169554875599726"}},"outputId":"5082dbef-0e86-4f60-b915-a49194bd3004"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ¯ Hafif eÄŸitim baÅŸladÄ± (max_len=120, batch=4, patience=3)\n","Epoch 1/50 | Loss: 518.4734\n","Epoch 2/50 | Loss: 446.0169\n","Epoch 3/50 | Loss: 443.7130\n","Epoch 4/50 | Loss: 460.1929\n","â¸ï¸  No improvement. Patience: 1/10\n","Epoch 5/50 | Loss: 442.2466\n","Epoch 6/50 | Loss: 441.8353\n","Epoch 7/50 | Loss: 476.0089\n","â¸ï¸  No improvement. Patience: 1/10\n","Epoch 8/50 | Loss: 442.1511\n","â¸ï¸  No improvement. Patience: 2/10\n","Epoch 9/50 | Loss: 456.8483\n","â¸ï¸  No improvement. Patience: 3/10\n","Epoch 10/50 | Loss: 441.3861\n","ğŸ’¾ KayÄ±t tamamlandÄ±: deeppersona_epoch10.pth\n","Epoch 11/50 | Loss: 441.2829\n","Epoch 12/50 | Loss: 587.9491\n","â¸ï¸  No improvement. Patience: 1/10\n","Epoch 13/50 | Loss: 442.7393\n","â¸ï¸  No improvement. Patience: 2/10\n","Epoch 14/50 | Loss: 534.1420\n","â¸ï¸  No improvement. Patience: 3/10\n","Epoch 15/50 | Loss: 468.7375\n","â¸ï¸  No improvement. Patience: 4/10\n","Epoch 16/50 | Loss: 441.1829\n","Epoch 17/50 | Loss: 584.4429\n","â¸ï¸  No improvement. Patience: 1/10\n","Epoch 18/50 | Loss: 442.6785\n","â¸ï¸  No improvement. Patience: 2/10\n","Epoch 19/50 | Loss: 616.8066\n","â¸ï¸  No improvement. Patience: 3/10\n","Epoch 20/50 | Loss: 789.6618\n","ğŸ’¾ KayÄ±t tamamlandÄ±: deeppersona_epoch20.pth\n","â¸ï¸  No improvement. Patience: 4/10\n","Epoch 21/50 | Loss: 455.4435\n","â¸ï¸  No improvement. Patience: 5/10\n","Epoch 22/50 | Loss: 510.6746\n","â¸ï¸  No improvement. Patience: 6/10\n","Epoch 23/50 | Loss: 465.0971\n","â¸ï¸  No improvement. Patience: 7/10\n","Epoch 24/50 | Loss: 796.6264\n","â¸ï¸  No improvement. Patience: 8/10\n","Epoch 25/50 | Loss: 472.6502\n","â¸ï¸  No improvement. Patience: 9/10\n","Epoch 26/50 | Loss: 444.3199\n","â¸ï¸  No improvement. Patience: 10/10\n","ğŸ›‘ Early stopping. Best Loss: 441.1829\n"]}]},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"deeppersona_best.pth\"))\n","model.eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bz-sweYePsq-","executionInfo":{"status":"ok","timestamp":1747586144981,"user_tz":-180,"elapsed":171,"user":{"displayName":"BÃ¼ÅŸra mina Al","userId":"10612169554875599726"}},"outputId":"c54fe8e9-337d-4e06-b493-6509fb2aef3b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LifeStoryModel(\n","  (embedding_layer): EmbeddingLayer(\n","    (projection): Sequential(\n","      (0): Linear(in_features=25, out_features=256, bias=True)\n","      (1): ReLU()\n","      (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (decoder): CharDecoder(\n","    (embedding): Embedding(74, 256)\n","    (layers): ModuleList(\n","      (0-3): 4 x TransformerBlock(\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=256, out_features=256, bias=True)\n","          (k_linear): Linear(in_features=256, out_features=256, bias=True)\n","          (v_linear): Linear(in_features=256, out_features=256, bias=True)\n","          (out): Linear(in_features=256, out_features=256, bias=True)\n","          (attn): ScaledDotProductAttention()\n","        )\n","        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (ff): Sequential(\n","          (0): Linear(in_features=256, out_features=512, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=512, out_features=256, bias=True)\n","        )\n","        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (output): Linear(in_features=256, out_features=74, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["def generate_text(model, persona_vec, char2idx, idx2char, max_len=120, temperature=0.9):\n","    model.eval()\n","    input_ids = [char2idx.get(\"B\", 0)]\n","    for _ in range(max_len):\n","        seq_tensor = torch.tensor(input_ids).unsqueeze(0)\n","        with torch.no_grad():\n","            logits = model(persona_vec.unsqueeze(0), seq_tensor)[0, -1]\n","            probs = F.softmax(logits / temperature, dim=0).cpu().numpy()\n","            next_id = np.random.choice(len(probs), p=probs)\n","        input_ids.append(next_id)\n","        if idx2char[next_id] == \"\\n\":\n","            break\n","    return \"\".join([idx2char[i] for i in input_ids])\n"],"metadata":{"id":"QpJQQvXHQGaT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install gradio Pillow\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6QmOMfcTJ9f","executionInfo":{"status":"ok","timestamp":1747587560295,"user_tz":-180,"elapsed":13924,"user":{"displayName":"BÃ¼ÅŸra mina Al","userId":"10612169554875599726"}},"outputId":"b45b9656-0cc2-4bf0-ff78-4c7274000421"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-5.29.1-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n","Collecting aiofiles<25.0,>=22.0 (from gradio)\n","  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting gradio-client==1.10.1 (from gradio)\n","  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n","Collecting groovy~=0.1 (from gradio)\n","  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.2)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Collecting ruff>=0.9.3 (from gradio)\n","  Downloading ruff-0.11.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n","Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n","  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-5.29.1-py3-none-any.whl (54.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.11.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n","Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n","Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.1 gradio-client-1.10.1 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.10 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"]}]},{"cell_type":"code","source":["!pip install gradio\n","import gradio as gr\n","from PIL import Image\n","import torch\n","import numpy as np\n","\n","\n","\n","def extract_visual_embedding(image: Image.Image):\n","    arr = np.array(image.resize((224, 224))).astype(np.float32) / 255.0\n","    features = [\n","        np.mean(arr), np.std(arr), np.min(arr), np.max(arr),\n","        *np.percentile(arr, [25, 50, 75])\n","    ]\n","    return torch.tensor(features + [0]*(25-len(features)), dtype=torch.float32)  # 25 boyut sabitlenmiÅŸ\n","\n","\n","def generate_text(model, persona_vec, char2idx, idx2char, max_len=300, temperature=1.1):\n","    model.eval()\n","    input_ids = [char2idx.get(\"B\", 0)]  # BaÅŸlangÄ±Ã§ karakteri\n","    for _ in range(max_len):\n","        seq_tensor = torch.tensor(input_ids).unsqueeze(0)\n","        with torch.no_grad():\n","            logits = model(persona_vec.unsqueeze(0), seq_tensor)[0, -1]\n","            probs = torch.softmax(logits / temperature, dim=0).cpu().numpy()\n","            next_id = np.random.choice(len(probs), p=probs)\n","        input_ids.append(next_id)\n","        if idx2char[next_id] == \"\\n\":\n","            break\n","    return \"\".join([idx2char[i] for i in input_ids])\n"],"metadata":{"id":"wz6AdQwcUz87","executionInfo":{"status":"error","timestamp":1747942181833,"user_tz":-180,"elapsed":171,"user":{"displayName":"BÃ¼ÅŸra mina Al","userId":"10612169554875599726"}},"outputId":"8e5048aa-6097-4f84-8c77-520ac5d4949f","colab":{"base_uri":"https://localhost:8080/","height":403}},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'gradio'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-05ef425892d2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gradio'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["def pipeline(image):\n","    vec = extract_visual_embedding(image)\n","    story = generate_text(model, vec, char2idx, idx2char)\n","    return story\n","\n","demo = gr.Interface(\n","    fn=pipeline,\n","    inputs=gr.Image(type=\"pil\", label=\"Bir yÃ¼z fotoÄŸrafÄ± yÃ¼kleyin\"),\n","    outputs=gr.Textbox(label=\"DeepPersona'nÄ±n yazdÄ±ÄŸÄ± hayat hikayesi\"),\n","    title=\"ğŸ§  BMinator â€“ AI Hikaye Ãœretici\",\n","    description=\"YÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼ne dayalÄ± olarak hayat hikayesi yazan Ã¼retken yapay zeka sistemine hoÅŸgeldiniz sonsuz hayal gÃ¼cÃ¼nÃ¼n tadÄ±nÄ± Ã§Ä±karÄ±n.\",\n",")\n","\n","demo.launch()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"GCtqxuuKVt0p","executionInfo":{"status":"ok","timestamp":1747587780085,"user_tz":-180,"elapsed":1349,"user":{"displayName":"BÃ¼ÅŸra mina Al","userId":"10612169554875599726"}},"outputId":"488dda94-07ee-4444-b91b-7b01d59636c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://1039420fb2cdacb01d.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://1039420fb2cdacb01d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":16}]}]}